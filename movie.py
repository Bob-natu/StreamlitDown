import cv2
import mediapipe as mp
import streamlit as st
import tempfile
import os
import numpy as np

# Streamlit UI è¨­å®š
st.title("ğŸ Volleyball Jump Analysis with MediaPipe")

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
uploaded_file = st.file_uploader("å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["mp4", "mov", "avi", "mkv"])

if uploaded_file:
    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    temp_video_path = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4').name
    with open(temp_video_path, "wb") as f:
        f.write(uploaded_file.read())
    
    # å‹•ç”»ã®åŸºæœ¬æƒ…å ±ã‚’å–å¾—
    cap = cv2.VideoCapture(temp_video_path)
    fps = cap.get(cv2.CAP_PROP_FPS)  # FPS ã¯å°æ•°ã®ã¾ã¾ä¿æŒ
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    st.write(f"**å‹•ç”»æƒ…å ±:** {width}x{height}, {fps:.2f} FPS, {total_frames} frames")
    
    # MediaPipe è¨­å®š
    mp_pose = mp.solutions.pose
    pose = mp_pose.Pose(static_image_mode=False, model_complexity=1, enable_segmentation=False)
    
    # æœ€ã‚‚ä½ã„ä½ç½®ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æ¢ã™
    min_y_value = float('inf')
    min_y_frame = 0
    
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        
        frame_count = int(cap.get(cv2.CAP_PROP_POS_FRAMES))
        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = pose.process(image_rgb)
        
        if results.pose_landmarks:
            left_heel_y = results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_HEEL].y * height
            right_heel_y = results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_HEEL].y * height
            avg_y = (left_heel_y + right_heel_y) / 2
            
            if avg_y < min_y_value:
                min_y_value = avg_y
                min_y_frame = frame_count
    
    cap.release()
    
    # åˆ‡ã‚Šå–ã‚Šç¯„å›²ã‚’è¨ˆç®—
    start_frame = max(0, min_y_frame - 0)
    end_frame = min(total_frames - 1, min_y_frame + 40)
    
    # å‡¦ç†å¾Œã®å‹•ç”»ã‚’ä¿å­˜ã™ã‚‹ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«
    output_video_path = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4').name
    cap = cv2.VideoCapture(temp_video_path)
    cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))
    
    # éª¨æ ¼è§£æã—ã¦æ–°ã—ã„å‹•ç”»ã‚’ä½œæˆ
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret or int(cap.get(cv2.CAP_PROP_POS_FRAMES)) > end_frame:
            break
        
        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = pose.process(image_rgb)
        
        if results.pose_landmarks:
            for landmark in [mp_pose.PoseLandmark.LEFT_SHOULDER, mp_pose.PoseLandmark.RIGHT_SHOULDER, 
                             mp_pose.PoseLandmark.LEFT_HEEL, mp_pose.PoseLandmark.RIGHT_HEEL]:
                lm = results.pose_landmarks.landmark[landmark]
                x, y = int(lm.x * width), int(lm.y * height)
                cv2.circle(frame, (x, y), 5, (0, 255, 0), -1)
        
        out.write(frame)
    
    cap.release()
    out.release()
    
    st.success("âœ… éª¨æ ¼è§£æãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    
    # å‡¦ç†å¾Œã®å‹•ç”»ã‚’è¡¨ç¤º
    st.video(output_video_path)
    
    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
    with open(output_video_path, "rb") as f:
        st.download_button(label="ğŸ“¥ å‡¦ç†æ¸ˆã¿å‹•ç”»ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=f, file_name="processed_video.mp4", mime="video/mp4")
